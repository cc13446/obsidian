# InnoDB存储引擎概述
第一个完整支持ACID事务的MySQL存储引擎，其特点是
1. 行锁设计
2. 支持MVCC
3. 支持外键
4. 提供一致性非锁定读
5. 更有效的利用内存和CPU

# InnoDB存储引擎的版本
| verson                       | 功能                            |
| ---------------------------- | ------------------------------- |
| 老版本InnoDB                 | 支持ACID、行锁设计、MVCC        |
| InnoDB 1.0.X / InnoDB Plugin | 增加`Compress`和`dynamic`页格式 |
| InnoDB 1.1.X                 | 增加Linux AIO、多回滚段         |
| InnoDB 1.2.X                 | 增加全文索引支持、在线索引添加  | 

# InnoDB体系架构
InnoDB存储引擎有多个内存块，可以认为这些内存块组成了一个大的内存池，负责：
1. 维护所有进程、线程需要访问的多个内部数据结构
2. 缓存磁盘上的数据，方便快速读取
3. 重组日志缓冲
4. ...

![](2.概述/Pasted%20image%2020220513123823.png)
## 后台线程
后台线程的主要作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存的是最近的数据，此外将已修改的数据文件刷新到磁盘文件中，同时保证在数据库发生异常的情况下InnoDB能恢复到正常运行状态。

### Master Thread
核心后台线程，负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性。包括：
1. 脏页的刷新
2. 合并插入缓冲
3. UNDO页的回收
4. ...

### IO Thread
在InnoDB中使用了大量的AIO来处理写IO请求，这样可以极大提高数据库的性能。而IO Thread的主要工作是负责这些IO请求的回调处理。目前有四种：
1. `write`
2. `read`
3. `insert buffer`
4. `log`

### Purge Thread
事务被提交之后，其所使用的undolog可能不再需要，因此需要Purge Thread来回收已经使用并分配的undo页。
1. `1.1`版本之前，purge操作在Master Thread完成
2. `1.1`版本开始，purge操作独立到单独的线程中进行
3. `1.2`版本开始，支持多个Purge Thread

### Page Cleaner Thread
1.2.X版本中引入，其作用是将之前版本中的脏页刷新操作放入单独的线程来完成，目的是减轻原Master Thread的工作及其对于用户查询线程的阻塞。

## 内存
### 缓冲池
一块内存区域，通过内存的速度来弥补磁盘速度较慢对数据库性能的影响。在数据库进行读取页的操作，首先将从磁盘读到的页存放在缓冲池中，下一次再读相同的页时首先判断该页是否在缓冲池中。若在缓冲池中则称该页在缓冲池中命中，直接读取该页。否则读取词盘上的页。

对于数据库中页的修改操作，则首先修改缓冲池中的页，然后再以一定的频率刷新到磁盘上。不是每次页发生更新时触发，而是通过Checkpoint的机制刷新回磁盘。

缓冲池在内存中的结构情况后：
![](2.概述/Pasted%20image%2020220513144812.png)
1.0.X版本开始，允许有多个缓冲池实例。每个页根据哈希值平均分配到不同缓冲池实例中。 可以减少数据库内部的资源竞争，增加数据库的并发处理能力

### LRU List、Free List 和 Flush List
数据库的缓冲池是通过LRU算法来进行管理的，即最频繁使用的页在LRU列表的前端，最少使用的页在LRU列表的尾端。当缓冲池不能存放新读取得页时，将首先释放LRU列表尾端的页。InnoDB存储引擎对于传统的LRU算法做了一些优化，加入了`midpoint`位置，新读取到的页并不是直接放入LRU列表的首部，而是放入到LRU列表的`midpoint`位置。这个算法叫`midpoint insertion strategy`。默认配置下，该位置在LRU列表长度的5/8处。InnoDB引擎中把`midpoint`之后的列表称为old列表，之前的列表称为new列表，也就是说new列表中都是最为活跃的热点数据。

采用这种方法的原因在于，遇到类似数据的扫描这种操作，需要访问数据库中的很多页，但是仅仅在这次查询操作中需要，并不是热点数据。如果采用原本的LRU算法，就会把其他的页都刷新出缓冲池，影响效率，所以采用这种方式来防止真正的热点数据被刷新出缓冲池。

那缓冲池中的页如何变成热点数据放到new列表中呢？InnoDB引擎由`innodb_old_blocks_time`参数表示页读取到mid位置后需要等待多久才被加入到LRU列表的热端。此时从LRU列表的old部分将页加入到new部分的操作就称为`page made young`，如果这个页没有等到足够的时间就被刷新出LRU列表了，也就不能移动到new部分，这个操作就叫`page not made young`。

Free列表管理着空闲页，可以用`SHOW ENGINE INNODB STATUS`命令来观察LRU列表和Free列表的运行情况，包括看到`page made young`和`page not made young`的情况，以及`Buffer pool hit rate`表示缓冲池命中率。

1.0.X版本开始支持压缩页的功能，将原本16KB的页压缩为1KB、2KB、4KB和8KB。由于页的大小发生了变化，对于非16KB的页是通过`unzip_LRU`列表进行管理的。`unzip_LRU`列表对于大小不同的压缩页进行分别管理，并通过伙伴算法来分配内存。通过一个例子理解`unzip_LRU`列表怎么从缓冲池中分配内存，假设要申请4KB的页：
1. 检查4KB的`unzip_LRU`列表，检查是否有空闲页
2. 有就直接用
3. 否则检查8KB的`unzip_LRU`列表
4. 如果能得到空闲页就把8KB的页分为两个4KB，存放到4KB的`unzip_LRU`列表
5. 如果不能得到空闲页，就从`LRU`列表中申请一个16KB的页，将页分为一个8KB两个4KB，分别存放

可以通过`information_schema`架构下的表`INNODB_BUFFER_PAGE_LRU`来观察`unzip_LRU`列表和LRU列表的各种信息。

LRU列表中的页被修改了以后，称该页为脏页。这时数据库会通过`CHECKPOINT`机制将脏页刷新回磁盘，而Flush List就是脏页列表。注意：脏页即存在于LRU列表中，也存在与Flush列表中。

表`INNODB_BUFFER_PAGE_LRU`加入`OLDEST_MODIFICATION > 0`的条件看脏页的元数据。

### 重做日志缓冲
存储引擎首先将重做日志放入重做日志缓冲区，然后按一定频率将其刷新到重做日志文件：
1. Master Thread 每一秒将重做日志缓冲刷新到文件
2. 每个事物提交时会将重做日志缓冲刷新到文件
3. 当重做日志缓冲池剩余空间小于1/2的时候，重做日志缓冲刷新到文件

### 额外的内存池
存储引擎对内存的管理是通过一种称为内存堆的方式进行的。在对一些数据结构本身的内存进行分配时，需要从额外的内存池中申请，当该区域的内存不够时，会从缓冲池中进行申请。每个缓冲池中的帧缓冲还有对应的缓冲控制对象的内存都需要从额外的内存池中申请，这些对象记录了诸如LRU、锁、等待等信息。因此缓冲池大的时候，也要增加额外的内存池。

## CheckPoint 技术
为了避免缓冲池中的脏页刷新到磁盘时发生宕机导致数据丢失，当前的数据库系统普遍都采用了`Write Ahead Log`策略，当事务提交时，先写重做日志，然后再修改页。当发生宕机的时候根据重写日志恢复数据。但是缓冲池不能无限大，重做日志也不能无限增长，而且要减少宕机之后重新应用重做日志的时间，所以要采用`CheckPoint`技术来解决以下问题：
1. 缩短数据库的恢复时间
2. 缓冲池不够用时，将脏页刷新到磁盘
3. 重做日志不可用时，刷新脏页

当数据库发生宕机，只需要对`CheckPoint`之后的重做日志进行恢复就可以了。

如果LRU算法溢出的是脏页，需要强行执行`CheckPoint`把脏页刷新回磁盘。

重做日志是循环使用的，如果要覆盖的日志已经不需要了就可以覆盖，否则就会出现重做日志不可用的情况，这个时候就必须`CheckPoint`来刷新当前重做日志的位置，创造出可以覆盖的日志。

引擎通过`Log Sequence Number, LSN`来标记`CheckPoint`，`LSN`是8字节的数字，每个页都有`LSN`，每个重做日志也有`LSN`，`CheckPoint`也有`LSN`。

两种`CheckPoint`:
1. `Sharp CheckPoint`：数据库关闭时将所有脏页刷新会磁盘
2. `Fuzzy CheckPoint`：运行期间刷新一部分脏页
	1. `Master Thread CheckPoint`：每秒或者每十秒刷新一定比例的脏页
	2. `FLUSH_LRU_LIST CheckPoint`：LRU列表要有100个空闲页，不够的话需要移除尾端的页
		- 如果有脏页就需要`CheckPoint`
		- 1.2.X版本放到了Page Cleaner线程中，`innodb_lru_scan_depth`控制空闲页数量
	3. `Async/Sync Flush CheckPoint`：重做日志不可用的情况
		- 定义：重做日志的LSN为`redo_lsn`，刷新回磁盘的LSN为`checkpoint_lsn`
		- 则有：`checkpoint_age = redo_lsn - checkpoint_lsn`
		- 定义：`async_water_mark = 0.75 * total_redo_log_file_size`
		- 定义：`sync_water_mark = 0.9 * total_redo_log_file_size`
		- `checkpoint_age < async_water_mark`：不需要刷新
		- `async_water_mark < checkpoint_age < sync_water_mark`：异步刷新
		- `checkpoint_age > sync_water_mark`：同步刷新
		- 异步刷新阻塞发现问题的用户查询线程，同步刷新阻塞所有的用户查询线程
		- 1.2.X版本以后，移到了Page Cleaner Thread，不会阻塞
	4. `Dirty Page too much CheckPoint`：脏页数量太多。
		- `innodb_max_dirty_page_pct`：脏页最大比例，超过就触发

## Master Thread 工作方式
### 1.0.X版本之前
具有最高的优先级，内部多个循环组成，Master Thread在多个循环内切换
1. `loop`：主循环
2. `background loop`：后台循环
3. `flush loop`：刷新循环
4. `suspend loop`：暂停循环

#### 主循环
包含一些每秒的操作和每10秒的操作，通过`sleep`完成，负载大的时候会有延迟
1. 每秒
	1. 日志缓冲刷新到磁盘，即是这个事务还没提交`总是`
	2. 合并插入缓冲`可能：IO次数大于5时`
	3. 至多刷新100个缓冲池中的脏页到磁盘`可能：脏页比例超过阈值`
	4. 如果用户没有当前用户活动，切换到后台循环`可能`
2. 每十秒
	1. 刷新100个脏页到磁盘`可能：脏页超过70%刷新100个，否则刷新10%`
	2. 合并至多五个插入缓冲`总是`
	3. 将日志缓冲刷新到磁盘`总是`
	4. 删除无用的undo页`总是`
	5. 刷新100个或者10个脏页到磁盘`总是：10秒内IO操作小于200次就刷100，否则10`

#### 后台循环
1. 删除无用的undo页`总是`
2. 合并20个插入缓冲`总是`
3. 跳转到刷新循环中`可能：脏页超过一定比例`
4. 跳回到主循环`总是`

#### 刷新循环
不断刷新100个页直到符合条件

#### 暂停循环
刷新循环中页没有事情可做了就切换到暂停循环，将Master Thread挂起，等待事件的发生

### 1.2.X版本之前
1.0.X版本之前规定了引擎对磁盘IO的性能，后来加入了参数`innodb_io_capacity`，用来表示磁盘IO的吞吐量，默认为200。对于刷新到磁盘页的数量，按照这个参数的百分比控制
1. 合并插入缓冲的数量为`innodb_io_capacity`的5%
2. 刷新脏页的数量为`innodb_io_capacity`

`innodb_max_dirty_pages_pct`的默认值从90变为75，加快刷新脏页的频率。

`innodb_adaptive_flushing`通过判断产生重做日志的速度来影响每秒刷新页的数量。

`innodb_purge_batch_size`参数可以控制每次full purge回收的Undo页的数量，默认20。

### 1.2.X版本
刷新脏页的操作交给`Page Cleaner Thread`

## InnoDB的关键特性
包括：
1. 插入缓冲
2. 两次写
3. 自适应哈希索引
4. 异步IO
5. 刷新临近页

### 插入缓冲
#### Insert Buffer
和数据页一样，也存在磁盘上，当然也在缓冲池中缓存。

在InnoDB引擎中，主键是行唯一的标识符。一般来说主键是自增长的，如果对主键插入`null`，则由于其具有`AUTO_INCREMENT`属性，其值会自动增长。由于主键上一般有聚集索引，所以页在磁盘上是顺序的。同时页中的行记录按主键的值进行顺序存放，在一般情况下不需要随机读取另一个页中的记录。因此对于这类情况的插入操作，速度是非常快的。

但是不可能只有聚集索引，还会有一些非聚集索引，当插入一条新数据的时候，对于非聚集索引的叶子节点就不是顺序读写了，这种随机读写导致了插入操作的性能下降。

InnoDB开创性的设计了Insert Buffer，对于非聚集索引的插入和更新操作，不是每次都直接插在索引页中，而是先判断其索引页是否在缓冲池中，若在则直接插入，否则先放到一个Insert Buffer对象中，然后再以一定的频率进行Insert Buffer和辅助索引子节点的合并操作。这时通常可以将多个插入合并到一个操作中，这样就大大提高了对于非聚集索引插入的性能。

Insert Buffer的使用需要满足两个条件
1. 索引是辅助索引
2. 索引不是唯一的：确保唯一性要在Insert Buffer中进行随机读取

但是要考虑一种情况，当大量的Insert Buffer没有被合并的时候发生了宕机，这个时候的恢复就需要很长时间。

目前存在的问题是，写密集的情况下，插入缓冲池会占用过多的缓冲池内存，默认最大可以占用到1/2的缓冲池内存，这会对其他操作带来影响。修改`IBUF_POOL_SIZE_PER_MAX_SIZE`就可以对插入缓冲的大小进行控制，默认值为2，代表最大用1/2。

#### Change Buffer
可以视为Insert Buffer的升级。从1.0.X版本开始，引擎可以对DML操作`INSERT`、`DELETE`、`UPDATE`进行缓冲，分别是Insert Buffer、Delete Buffer、Purge Buffer。依然适用于非唯一的辅助索引。

对一条记录进行UPDATE操作有两个过程
1. 将记录标记为已删除：`Delete Buffer`
2. 真正将记录删除：`Purge Buffer`

也可以用参数控制Change Buffer对各种操作是否开启，以及占用缓冲池的大小。

#### Insert Buffer的内部实现
他的数据结构是一颗B+数，`Mysql 4.1`版本之前是每张表一个，现在则是全局一个，负责对所有表的辅助索引进行`Insert Buffer`，默认放在共享表空间中，也就是`ibdata1`中。

非叶子节点存放查询的`search key`
![](2.概述/Pasted%20image%2020220514145233.png)
当一个辅助索引要插入到页中时，如果这个页不在缓冲池里面，那么`InnoDB`存储引擎首先构建一个上面的`search key`，然后查询`Insert Buffer`的B+树，再将记录插入到叶子节点中。插入的时候，需要按照以下方式构造：
![](2.概述/Pasted%20image%2020220514150038.png)

同时还需要一个特殊的页来标记每个辅助索引页的可用空间，来保证每次`Merge Insert Buffer`必须成功。这个页的类型为`Insert Buffer Bitmap`。每个`Insert Buffer Bitmap`追踪16384个辅助索引页，并且放在16384的页中的第二个页中。每个辅助索引页在`Insert Buffer Bitmap`占用四位：

| 名称                   | 大小/bit | 说明                                                |
| ---------------------- | -------- | --------------------------------------------------- |
| `IBUF_BITMAP_FREE`     | 2        | 可用空间                                            |
| `IBUF_BITMAP_BUFFERED` | 1        | 1表示该辅助索引页有记录被缓存在Insert Buffer B+树中 |
| `IBUF_BITMAP_IBUF`     | 1        | 1表示该页为Insert Buffer B+树的索引页               | 

`IBUF_BITMAP_FREE`：
- 0代表无可用剩余空间
- 1代表剩余的空间大于1/32，512字节
- 2代表剩余的空间大于1/16
- 3代表剩余的空间大于1/8

#### Merge Insert Buffer
合并的操作发生在以下几种情况
1. 索引辅助页被读取到缓冲池中
2. `Insert Buffer Bitmap`页追踪到该辅助索引页无可用空间时
3. Master Thread

第一种情况，需要根据`Insert Buffer Bitmap`页确认该辅助索引页是否在`Insert Buffer`中有记录。若有，则将`Insert Buffer`中该页的记录插入到该辅助索引页中。该页多次的记录操作通过一次操作合并到了原有的辅助索引页中，性能会有大幅提高。  
  
第二种情况，若插入辅助索引记录时检测到插入记录后可用空间会小于1/32页，则会强制进行一个合并操作。  
  
第三种情况，Master线程每秒或每10秒会进行一次`Merge Insert Buffer`的操作，不同之处在于每次进行合并操作的页的数量不同。

### 两次写
带来数据页的可靠性。当数据库宕机的时候，可能某个页只写了一部分，这叫做**部分写失效**。也许可以通过重做日志恢复，但是必须认识到重做日志中记录的是对页的物理操作，如果这个页发生了损坏，再对其进行重做是没有意义的。我们需要一个页的副本来还原这个页，再进行重做。

`doublewrite`由两部分组成
1. 内存中的`doublewrite buffer`，大小为2MB
2. 物理磁盘上共享表空间中连续的128页，两个区，大小同样为2MB

![](2.概述/Pasted%20image%2020220514154749.png)

在对脏页进行刷新的时候，并不直接写磁盘，而是先通过`MEMCPY`函数先将脏页复制到内存中的`doublewrite buffer`，然后通过`doublewrite buffer`再分两次，每次1MB顺序的写到共享表空间的物理磁盘上，然后马上调用`fsync`函数同步磁盘。在这个过程中是连续读写所以开销不是很大。然后再将`doublewrite buffer`中的页写入各个表空间的文件里，此时写入是离散的。如果发生了部分写失效就可以用共享表空间中的副本对损坏的页进行恢复了。

### 自适应哈希存储
存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引提升速度，则建立哈希索引，称之为自适应哈希索引`Adaptive Hash Index，AHI`。AHI是通过缓冲池的B+树页构造而来，因此建立的速度很快，而且不需要对整张表构建哈希索引。InnoDB会自动根据访问的频率和模式来自动地为热点页建立哈希索引。  
  
AHI的要求：  
1. 对这个页的连续访问模式必须是一样的，即`where`条件一样
2. 以该模式访问了100次
3. 页通过该模式访问了N次，其中`N=页中记录*1/16`  
  
官方文档显示，启用AHI后，读取和写入速度可以提高2倍，辅助索引的连接操作性能可以提高5倍。AHI是非常好的优化模式，其设计思想是数据库自优化的。  
  
哈希索引只能用来搜索等值的查询，如`WHERE index_col='xxx'`。而对于如范围查找，不能使用哈希索引。参数`innodb_adaptive_hash_index`用来禁用或启动此特性，默认AHI为开启状态。

### 异步IO

为了提高磁盘操作性能，数据库系统都采用异步IO `Asynchronous IO，AIO`的方式来处理磁盘操作，InnoDB也是。  异步IO就是，在发出一个IO请求后立即再发出另一个IO请求，当全部IO请求发送完毕后，等待所有IO操作的完成。  
  
AIO的另一个优势是可以进行IO Merge操作，多个IO合并为1个IO，可以提高IOPS的性能。  
  
在`1.1.x`之前，AIO的实现是通过代码来模拟实现。而从`1.1.x`开始，提供了内核级别AIO的支持，称为`Native AIO`。`Native AIO`需要操作系统提供支持。Windows系统和Linux系统都提供`Native AIO`支持，而Mac OSX系统则未提供。  
  
参数`innodb_use_native_aio`用来控制是否启用`Native AIO`，在Linux下，默认值为ON。  
  
官方的测试显示，启用`Native AIO`，恢复速度可以提高75%。

### 刷新邻接页

InnoDB还提供了刷新邻接页`Flush Neighbor Page`的特性。原理是：当刷新一个脏页时，会检测该页所在区的所有页，如果是脏页，那么一起进行刷新。这样做的好处显而易见。对传统机械磁盘有显著的优势。但是需要考虑到下面两个问题：  
1. 是不是可能将不怎么脏的页进行了写入，而该页之后又会很快变成脏页？  
2. 固态硬盘有着较高的IOPS，是否还需要这个特性？  
  
为此，从1.2.x版本开始提供了参数`innodb_flush_neighbors`，用来控制是否启用该特性。对于传统机械硬盘建议启用该特性，而对于固态硬盘有着超高IOPS性能的磁盘，则建议关闭。


