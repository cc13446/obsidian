# 事务
事务会把数据库从一种一致状态转换为另一种一致状态。在数据库提交工作时，可以确保要么所有修改都已经保存了，要么所有修改都不保存。

InnoDB存储引擎中的事务完全符合ACID的特性。ACID是以下4个词的缩写：
1. 原子性`atomicity`：整个数据库事务是不可分割的工作单位
2. 一致性`consistency`：事务开始之前和事务结束以后，数据库的完整性约束没有被破坏
3. 隔离性`isolation`：每个读写事务的对象对其他事务的操作对象能相互分离
4. 持久性`durability`：事务一旦提交，其结果就是永久性的

## 认识事务
### 概述
事务可由一条非常简单的SQL语句组成，也可以由一组复杂的SQL语句组成。事务是访问并更新数据库中各种数据项的一个程序执行单元。在事务中的操作，要么都做修改，要么都不做，这就是事务的目的，也是事务模型区别与文件系统的重要特征之一。

理论上说，事务有着极其严格的定义，它必须同时满足四个特性，即通常所说的事务的ACID特性。值得注意的是，虽然理论上定义了严格的事务要求，但是数据库厂商出于各种目的，并没有严格去满足事务的ACID标准。

### 分类
从事务理论的角度来说，可以把事务分为以下几种类型：
1. 扁平事务`Flat Transactions`
2. 带有保存点的扁平事务`Flat Transactions with Savepoints`
3. 链事务`Chained Transactions`
4. 嵌套事务`Nested Transactions`
5. 分布式事务`Distributed Transactions`

对于`InnoDB`存储引擎来说，其支持扁平事务、带有保存点的事务、链事务、分布式事务。对于嵌套事务，其并不原生支持，然而用户仍可以通过带有保存点的事务来模拟串行的嵌套事务。

#### 扁平事务
扁平事务是事务类型中最简单的一种，但在可能是生产环境中使用最为频繁的事务。扁平事务中，所有操作都处于同一层次，其由`BEGIN WORK`开始，由`COMMIT WORK`或`ROLLBACK WORK`结束，其间的操作是原子的，要么都执行，要么都回滚。因此扁平事务是应用程序成为原子操作的基本组成模块。扁平事务有三种结果
1. 成功完成：96%
2. 应用程序要求停止事务：3%
3. 强制终止事务，由于外界原因回滚：1%

主要限制是不能提交或者回滚事务的某一部分，或分几个步骤提交

#### 带有保存点的扁平事务
针对扁平事务必须不能分步骤提交的问题，有了带有保存点的扁平事务，除了支持扁平事务支持的操作外，允许在事务执行过程中回滚到同一事务中较早的一个状态。这是因为某些事务可能在执行过程中出现的错误并不会导致所有的操作都无效，放弃整个事务不合乎要求，开销也太大。保存点用来通知系统应该记住事务当前的状态，以便当之后发生错误时，事务能回到保存点当时的状态。

对于扁平的事务来说，其隐式地设置了一个保存点。然而在整个事务中，只有这一个保存点，因此，回滚只能回滚到事务开始时的状态。保存点用`SAVE WORK`函数来建立，通知系统记录当前的处理状态。当出现问题时，保存点能用作内部的重启动点，根据应用逻辑，决定是回到最近一个保存点还是其他更早的保存点。

#### 链事务
可视为保存点模式的一种变种。带有保存点的扁平事务，当发生系统崩溃时，所有的保存点都将消失，因为其保存点是易失的，而非持久的 。这意味着当进行恢复时，事务需要从开始处重新执行，而不能从最近的一个保存点继续执行。

链事务的思想是：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。注意，提交事务操作和开始下一个事务操作将合并为一个原子操作。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中进行的一样。

![](7.事务/Pasted%20image%2020220518110043.png)

链事务与带有保存点的扁平事务不同的是，带有保存点的扁平事务能回滚到任意正确的保存点。而链事务中的回滚仅限于当前事务，即只能恢复到最近一个的保存点。对于锁的处理，两者也不相同。链事务在执行 `COMMIT`后即释放了当前事务所持有的锁，而带有保存点的扁平事务不影响迄今为止所持有的锁。

#### 嵌套事务
嵌套事务是一个层次结构框架。由一个顶层事务控制着各个层次的事务。顶层事务之下嵌套的事务被称为子事务，其控制每一个局部的变换。

![](7.事务/Pasted%20image%2020220518114550.png)

嵌套事务的定义：
1. 嵌套事务是由若干事务组成的一棵树，子树既可以是嵌套事务，也可以是扁平事务。
2. 处在叶节点的事务是扁平事务。但是每个子事务从根到叶节点的距离可以是不同的。
3. 位于根节点的事务称为顶层事务，其他事务称为子事务。
4. 事务的前驱称为父事务，事务的下一层称为儿子事务。
5. 子事务既可以提交也可以回滚。但是它的提交操作并不马上生效，除非其父事务已经提交。因此可以推论出，任何子事物都在顶层事务提交后才真正的提交。
6. 树中的任意一个事务的回滚会引起它的所有子事务一同回滚，故子事务仅保留ACI特性，无D。

在Moss的理论中，实际的工作是交由叶子节点来完成的，即只有叶子节点的事务才能访问数据库、发送消息、获取其他类型的资源。而高层的事务仅负责逻辑控制，决定何时调用相关的子事务。

即使一个系统不支持嵌套事务，用户也可以通过保存点技术来模拟嵌套事务。但是用保存点技术来模拟嵌套事务在锁的持有方面还是与嵌套查询有些区别。当通过保存点技术来模拟嵌套事务时，用户无法选择哪些锁需要被子事务继承，哪些需要被父事务保留。这就是说，无论有多少个保存点，所有被锁住的对象都可以被得到和访问。而在嵌套查询中，不同的子事务在数据库对象上持有的锁是不同的。

#### 分布式事务
通常是一个在分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点。

## 事务的实现
ACID的实现：
1. 事务隔离性由锁和`MVCC`来实现。
2. `redo log`称为重做日志，用来保证事务的原子性和持久性。
3. `undo log`用来保证事务的一致性，帮助事务回滚及`MVCC`的实现。

`redo`和`undo`的作用都可以视为是一种恢复操作：
1. `redo`恢复提交事务修改的页操作
2. `undo`回滚行记录到某个特定版本

两者记录的内容不同：
1. `redo`通常是物理日志，记录的是页的物理修改操作
2. `undo`是逻辑日志，根据每行记录进行记录

### redo
#### 基本概念
重做日志用来实现事务的持久性，即事务ACID中的D。其由两部分组成：
1. 内存中的重做日志缓冲，其是易失的；
2. 二是重做日志文件，其是持久的。

InnoDB是事务的存储引擎，通过`Force Log at Commit`机制实现事务的持久性，即当事务提交的时候，必须先确定该事务的所有日志都已经写入到重做日志文件进行持久化，该事务的`COMMIT`操作完成才算完成。`redo log`基本上都是顺序写的，在数据库运行时不需要对`redo log`的文件进行读取操作。

由于重做日志文件打开并没有使用`O_DIRECT`选项，因此重做日志缓冲先写入文件系统缓存。为了确保重做日志写入磁盘，必须进行一次`fsync`操作。

参数`innodb_flush_log_at_trx_commit`用来控制重做日志刷新到磁盘的策略。
- 默认值为1，表示事务提交时必须调用一次`fsync`操作
- 0表示事务提交时不写入重做日志，在`master thread`中每1秒会写入一次并进行`fsync`操作
- 2表示事务提交时将重做日志写入文件系统的缓存中，不进行`fsync`操作

也就是说，一个没有提交事务的`redo log`记录，也可能会刷盘。因为在事务执行过程`redo log`记录是会写入`redo log buffer`中，这些`redo log`记录会被后台线程刷盘。

与二进制日志的区别：
1. 重做日志是在InnoDB存储引擎层产生，而二进制日志是在MySQL数据库的上层产生的
2. 内容形式不同
	1. MySQL数据库上层的二进制日志是一种逻辑日志，其记录的是对应的SQL语句
	2. InnoDB存储引擎层面的重做日志是物理格式日志，其记录的是对于每个页的修改
3. 写入磁盘的时间点不同
	1. 二进制日志只在事务提交完成后进行一次写入
	2. InnoDB存储引擎的重做日志在事务进行中不断地被写入

#### log block
在InnoDB存储引擎中，重做日志都是以512字节进行存储的。这意味着重做日志缓存、重做日志文件都是以块的方式进行保存的，称之为重做日志块，每块的大小为512字节，和磁盘扇区大小一样，可以保证原子性不需要`doublewrite`技术。

重做日志块除了日志本身之外，还由日志块头及日志块尾两部分组成。重做日志头一共占用12字节，重做日志尾占用8字节。故每个重做日志块实际可以存储的大小为492字节。

![](7.事务/Pasted%20image%2020220518152229.png)

`log block header`由4部分组成：
1. `LOG_BLOCK_HDR_NO`：用来标记此`Block`在`Log Buffer`的位置。
	- 其是递增并且循环使用的，占用4个字节
2. `LOG_BLOCK_HDR_DATA_LEN`：占用2字节，表示`log block`所占用的大小。
3. `LOG_BLOCK_FIRST_REC_GROUP`：占用2个字节
	- 表示`log block`中第一个新的日志所在的偏移量，也就是指向事务的头
	- 如果该值的大小和`LOG_BLOCK_HDR_DATA_LEN`相同，则表示当前`log block`不包含新的日志
4. `LOG_BLOCK_CHECKPOINT_NO`：占用4字节，表示该`log block`最后被写入时的检查点的4字节

`log block tailer`只由1个`LOG_BLOCK_TRL_NO`组成，且其值和`LOG_BLOCK_HDR_NO`相同。

#### log group
`log group`是重做日志组，其中有多个重做日志文件。虽然源码中已支持`log group`的镜像功能，但是在`ha_innobase.cc`文件中禁止了该功能。因此`InnoDB`存储引擎实际只有一个`log group`。

重做日志文件的总大小有一次改动
- 在`InnoDB 1.2`版本之前，重做日志文件的总大小要小于4GB（不能等于4GB） 
- 从`InnoDB 1.2`版本开始重做日志文件总大小的限制提高为了512GB

`log buffer`根据一定的规则将内存中的`log block`刷新到磁盘。这个规则具体是：
1. 事务提交时
2. 当`log buffer`中有一半的内存空间已经被使用时
3. `log checkpoint`

`log block`的写入会追加在`redo log file`的最后部分，当一个`redo log file`被写满时，会接着写入下一个`redo log file`，其使用方式为轮询`round-robin`。

每个`redo log file`的前2KB的部分不保存`log block`的信息。对于`log group`中的第一个`redo log file`，其前2KB的部分保存4个512字节大小的块。

![](7.事务/Pasted%20image%2020220518190233.png)

上述信息仅在每个`log group`的第一个`redo log file`中进行存储。`log group`中的其余`redo log file`仅保留这些空间，但不保存上述信息。正因为保存了这些信息，就意味着对`redo log file`的写入并不是完全顺序的。因为其除了`log block`的写入操作，还需要更新前2KB部分的信息，这些信息对于`InnoDB`存储引擎的恢复操作来说非常关键和重要。

`log group`与`redo log file`之间的关系如下：
![](7.事务/Pasted%20image%2020220518190402.png)

在`log filer header`后面的部分为`InnoDB`存储引擎保存的`checkpoint`，其设计是交替写入，这样的设计避免了因介质失败而导致无法找到可用的`checkpoint`的情况。

#### 重做日志格式
由于InnoDB存储引擎的存储管理是基于页的，故其重做日志格式也是基于页的。虽然有着不同的重做日志格式，但是它们有着通用的头部格式，通用的头部格式由以下3部分组成：
1. `redo_log_type`：重做日志的类型
2. `space`：表空间的ID
3. `page_no`：页的偏移量
4. `redo log body`：根据重做日志类型的不同，会有不同的存储内容

到`InnoDB1.2`版本时，一共有51种重做日志类型。随着功能不断地增加，相信会加入越来越多的重做日志类型。

#### LSN
LSN是`Log Sequence Number`的缩写，其代表的是日志序列号。在InnoDB存储引擎中，LSN占用8字节，并且单调递增。LSN表示的含义有：
1. 重做日志写入的总量，其单位为字节。
2. `checkpoint`的位置：每个页的头部的`FIL_PAGE_LSN`，表示该页最后刷新时LSN的大小
3. 页的版本

因为重做日志记录的是每个页的日志，因此页中的LSN用来判断页是否需要进行恢复操作。例如，页`P1`的LSN为`10000`，而数据库启动时，InnoDB检测到写入重做日志中的LSN为`13000`，并且该事务已经提交，那么数据库需要进行恢复操作，将重做日志应用到P1页中。同样的，对于重做日志中LSN小于`P1`页的LSN，不需要进行重做，因为P1页中的LSN表示页已经被刷新到该位置。

`SHOW ENGINE INNODB STATUS`查看LSN的情况：
1. `Log sequence number`表示当前的LSN
2. `Log flushed up to`表示刷新到重做日志文件的LSN
3. `Last checkpoint at`表示刷新到磁盘的LSN

虽然在上面的例子中，`Log sequence number`和`Log flushed up to`的值是相同的，但是在实际生产环境中，该值有可能是不同的。因为在一个事务中从日志缓冲刷新到重做日志文件并不只是在事务提交时发生，每秒都会有从日志缓冲刷新到重做日志文件的动作。

#### 恢复
`InnoDB`存储引擎在启动时不管上次数据库运行时是否正常关闭，都会尝试进行恢复操作。因为重做日志记录的是物理日志，因此恢复的速度比逻辑日志，如二进制日志，要快很多。与此同时，存储引擎自身也对恢复进行了一定程度的优化，如顺序读取及并行应用重做日志，这样可以进一步地提高数据库恢复的速度。在恢复过程中仅需恢复`checkpoint`开始的日志部分。

![](7.事务/Pasted%20image%2020220518193430.png)

### undo
#### 基本概念
`InnoDB`存储引擎不但会产生`redo`，还会产生一定量的`undo`。这样如果用户执行的事务或语句由于某种原因失败了，又或者用户用一条`ROLLBACK`语句请求回滚，就可以利用这些`undo`信息将数据回滚到修改之前的样子。

`undo`存放在数据库内部的一个特殊段中，这个段称为`undo`段。`undo`段位于共享表空间内。`undo`是逻辑日志，因此只是将数据库逻辑地恢复到原来的样子，但是数据结构和页本身在回滚之后可能大不相同。因为在多用户并发系统中，可能会有数十、数百甚至数千个并发事务。数据库的主要任务就是协调数据记录的并发访问。比如，一个事务在修改当前一个页中某几条记录，同时还有别的事务在对同一个页中另几条记录进行修改。因此，不能将一个页回滚到事务开始的样子，因为这样会影响其他事务正在进行的工作

例如，用户执行了一个`INSERT 10W`条记录的事务，这个事务会导致分配一个新的段，即表空间会增大。在用户执行`ROLLBACK`时，会将插入的事务进行回滚，但是表空间的大小并不会因此而收缩。因此，当InnoDB存储引擎回滚时，它实际上做的是与先前相反的工作：
1. 对于每个`INSERT`，InnoDB存储引擎会完成一个`DELETE`
2. 对于每个`DELETE`，InnoDB存储引擎会执行一个`INSERT`
3. 对于每个`UPDATE`，InnoDB存储引擎会执行一个相反的`UPDATE`，将修改前的行放回去

除了回滚操作，`undo`的另一个作用是`MVCC`，即在InnoDB存储引擎中`MVCC`的实现是通过`undo`来完成。当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过`undo`读取之前的行版本信息，以此实现非锁定读取。

最后也是最为重要的一点是，`undo log`会产生`redo log`，也就是`undo log`的产生会伴随着`redo log`的产生，这是因为`undo log`也需要持久性的保护。

#### undo存储管理
`InnoDB`存储引擎对`undo`的管理同样采用段的方式。但是这个段和之前介绍的段有所不同。首先存储引擎有`rollback segment`，每个回滚段中记录了1024个`undo log segment`，而在每个`undo log segment`段中进行`undo`页的申请。共享表空间偏移量为5的页记录了所有`rollback segment header`所在的页，这个页的类型为`FIL_PAGE_TYPE_SYS`。

##### 回滚段的版本改动
1. 在`InnoDB 1.1`版本之前，只有一个回滚段，因此支持同时在线的事务限制为1024。
2. 在`InnoDB 1.1`版本开始支持最大`128`个回滚段，支持同时在线的事务限制提高到了`128*1024`
	- 这些`rollback segment`都存储于共享表空间中
3. `InnoDB1.2`版本开始，可通过参数对回滚段做进一步的设置。这些参数包括：
	1. `innodb_undo_directory`：设置回滚段文件所在的路径，可以设置为独立表空间
	2. `innodb_undo_logs`：设置回滚段的个数，默认值为128
	3. `innodb_undo_tablespaces`：设置构成回滚段文件的数量

##### 事务提交时
需要特别注意的是，事务在`undo log segment`分配页并写入`undo log`的这个过程同样需要写入重做日志。当事务提交时，InnoDB存储引擎会做以下两件事情：
1. 将`undo log`放入列表中，以供之后的`purge`操作
2. 判断`undo log`所在的页是否可以重用，若可以分配给下个事务使用

##### 事务提交后
事务提交后并不能马上删除`undo log`及`undo log`所在的页。这是因为可能还有其他事务需要通过`undo log`来得到行记录之前的版本。故事务提交时将`undo log`放入一个链表中，是否可以最终删除`undo log`及`undo log`所在页由`purge`线程来判断。

此外，若为每一个事务分配一个单独的`undo`页会非常浪费存储空间，特别是对于OLTP的应用类型。因为在事务提交时，可能并不能马上释放页。

##### Undo页重用
因此，在`InnoDB`存储引擎的设计中对`undo`页可以进行重用。具体来说，当事务提交时，首先将`undo log`放入链表中，然后判断`undo`页的使用空间是否小于`3/4`，若是则表示该`undo`页可以被重用，之后新的`undo log`记录在当前`undo log`的后面。由于存放`undo log`的列表是以记录进行组织的，而`undo`页可能存放着不同事务的`undo log`，因此`purge`操作需要涉及磁盘的离散读取操作，是一个比较缓慢的过程。

#### undo log格式
在InnoDB存储引擎中，`undo log`分为：
1. `insert undo log`
2. `update undo log`

`insert undo log`是指在`insert`操作中产生的`undo log`。因为`insert`操作的记录，只对事务本身可见，对其他事务不可见，故该`undo log`可以在事务提交后直接删除。不需要进行`purge`操作。

`update undo log`记录的是对`delete`和`update`操作产生的`undo log`。该`undo log`可能需要提供`MVCC`机制，因此不能在事务提交时就进行删除。提交时放入`undo log`链表，等待`purge`线程进行最后的删除。

#### delete 的实现
`delete`操作并不直接删除记录，而只是将记录标记为已删除，也就是将记录的`delete flag`设置为1。而记录最终的删除是在`purge`操作中完成的。

#### update的实现
`update`主键的操作其实分两步完成。
1. 将原主键记录标记为已删除，产生类型为`TRX_UNDO_DEL_MARK_REC`的`undo log`
2. 之后插入一条新的记录，因此需要产生一个类型为`TRX_UNDO_INSERT_REC`的`undo log`

### purge
`delete`和`update`操作可能并不直接删除原有的数据。
```sql
-- 假设有这样一个表：
CREATE TABLE t(
a INT,
b VARCHAR(32),
PRIMARY KEY(a),
KEY(b)
)ENGINE=InnoDB;

--执行如下的SQL语句：

DELETE FROM t WHERE a=1;
```

表`t`上列`a`有聚集索引，列`b`上有辅助索引。对于上述的`delete`操作仅是将主键列等于`1`的记录的`delete flag`设置为1，记录并没有被删除，即记录还是存在于B+树中。其次，对辅助索引上`a`等于`1`的记录同样没有做任何处理，甚至没有产生`undo log`。而真正删除这行记录的操作其实被延时了，最终在`purge`操作中完成。

`purge`用于最终完成`delete`和`update`操作。这样设计是因为InnoDB存储引擎支持`MVCC`，所以记录不能在事务提交时立即进行处理。这时其他事物可能正在引用这行，故InnoDB存储引擎需要保存记录之前的版本。而是否可以删除该条记录通过`purge`来进行判断。若该行记录已不被任何其他事务引用，那么就可以进行真正的`delete`操作。

`InnoDB`存储引擎的`undo log`设计是这样的：一个页上允许多个事务的`undo log`存在。虽然这样后面的事务产生的`undo log`总在最后，但是这不能代表事务在全局过程中提交的顺序。所以为了跟踪事务提交的顺序，InnoDB存储引擎还有一个`history`列表，它根据事务提交的顺序，将`undo log`进行链接，先提交的事务总在尾端。在执行`purge`的过程中，InnoDB存储引擎首先从`history list`的尾端开始清理。

![](7.事务/Pasted%20image%2020220519121334.png)

### group commit
为了提高磁盘`fsync`的效率，当前数据库都提供了`group commit`的功能，即一次`fsync`可以刷新确保多个事务日志被写入文件。对于InnoDB存储引擎来说，事务提交时会进行两个阶段的操作：
1. 修改内存中事务对应的信息，并且将日志写入重做日志缓冲。
2. 调用`fsync`将确保日志都从重做日志缓冲写入磁盘。

步骤2相对步骤1是一个较慢的过程，这是因为存储引擎需要与磁盘打交道。但当有事务进行这个过程时，其他事务可以进行步骤1的操作，正在提交的事物完成提交操作后，再次进行步骤2时，可以将多个事务的重做日志通过一次`fsync`刷新到磁盘，这样就大大地减少了磁盘的压力，从而提高了数据库的整体性能。对于写入或更新较为频繁的操作，`group commit`的效果尤为明显。

然而在InnoDB1.2版本之前，在开启二进制日志后，InnoDB存储引擎的`group commit`功能会失效，从而导致性能的下降。并且在线环境多使用`replication`环境，因此二进制日志的选项基本都为开启状态，因此这个问题尤为显著。

导致这个问题的原因是在开启二进制日志后，为了保证存储引擎层中的事务和二进制日志的一致性，二者之间使用了两阶段事务，其步骤如下：
1. 当事务提交时`InnoDB`存储引擎进行`prepare`操作
2. MySQL数据库上层写入二进制日志
3. InnoDB存储引擎层将日志写入重做日志文件
	1. 修改内存中事务对应的信息，并且将日志写入重做日志缓冲
	2. 调用fsync将确保日志都从重做日志缓冲写入磁盘

一旦步骤2中的操作完成，就确保了事务的提交，即使在执行步骤3时数据库发生了宕机。此外需要注意的是，每个步骤都需要进行一次`fsync`操作才能保证上下两层数据的一致性。
- 步骤2的`fsync`由参数`sync_binlog`控制
- 步骤3的`fsync`由参数`innodb_flush_log_at_trx_commit`控制

为了保证MySQL数据库上层二进制日志的写入顺序和`InnoDB`层的事务提交顺序一致，MySQL数据库内部使用了`prepare_commit_mutex`这个锁。但是在启用这个锁之后，步骤3中的步骤a不可以在其他事务执行步骤b时进行，从而导致了`group commit`失效。

MySQL 5.6采用的解决方案为`Binary Log Group Commit，BLGC`。
![](7.事务/Pasted%20image%2020220519124350.png)

在MySQL数据库上层进行提交时按顺序将其放入一个队列中，队列中的第一个事务称为`leader`，其他事务称为`follower`，`leader`控制着`follower`的行为。`BLGC`的步骤分为以下三个阶段：
1. `Flush`阶段，将每个事务的二进制日志写入内存中。
2. `Sync`阶段，将内存中的二进制日志刷新到磁盘，
	- 若队列中有多个事务，那么仅一次`fsync`操作就完成了二进制日志的写入，这就是`BLGC`
3. `Commit`阶段，`leader`根据顺序调用存储引擎层事务的提交
	- `InnoDB`本就支持`group commit`
	- 修复了原先由于锁`prepare_commit_mutex`导致`group commit`失效的问题

当有一组事务在进行`Commit`阶段时，其他新事务可以进行`Flush`阶段，从而使`group commit`不断生效。当然`group commit`的效果由队列中事务的数量决定，若每次队列中仅有一个事务，那么可能效果和之前差不多，甚至会更差。但当提交的事务越多时，`group commit`的效果越明显，数据库性能的提升也就越大。

参数`binlog_max_flush_queue_time`用来控制Flush阶段中等待的时间，即使之前的一组事务完成提交，当前一组的事务也不马上进入`Sync`阶段，而是至少需要等待一段时间。这样做的好处是`group commit`的事务数量更多，然而这也可能会导致事务的响应时间变慢。该参数的默认值为0，且推荐设置依然为0。除非用户的MySQL数据库系统中有着大量的连接，并且不断地在进行事务的写入或更新操作。