## 哈希表
### 数据结构
```go
type hmap struct {
	count     int             // 当前哈希表中的元素数量
	flags     uint8           // 状态标识，goroutine 写入和扩容机制的相关状态控制
	B         uint8           // 当前哈希表持有的 buckets 数组长度 len(buckets) == 2^B
	noverflow uint16          // 溢出桶的数量
	hash0     uint32          // 哈希的种子，它能为哈希函数的结果引入随机性

	buckets    unsafe.Pointer // 数据数组
	oldbuckets unsafe.Pointer // 扩容时用于保存之前的数组，大小是当前 buckets 的一半
	nevacuate  uintptr        // 迁移进度

	extra *mapextra
}

type mapextra struct {
	overflow    *[]*bmap      // 当前溢出桶的指针地址
	oldoverflow *[]*bmap      // 旧溢出桶的指针地址
	nextOverflow *bmap        // 空闲溢出桶的指针地址
}
```

`hmap.buckets`是一`bmap`数组，每个`bmap`都能存储8个键值对，当哈希表中存储的数据过多，单个桶已经装满时就会使用 `extra.nextOverflow` 中的桶存储溢出的数据。

```go
type bmap struct {
    topbits  [8]uint8     // key 的 hash 值高 8 位，减少访问键值对的次数
    keys     [8]keytype
    values   [8]valuetype
    pad      uintptr
    overflow uintptr      // 下一个溢出桶的指针地址
}
```

这里的 `key` 和 `value` 不是穿插着存储的，而是相同的存储在一块儿，这样可以保证内存对齐。

### Map 的 GC 问题
当`map`的`key`和`value`都不包含指针时，在GC期间就可以避免对其扫描，提升不少性能。

在GC的时候应该扫描`BMAP`中的所有指针，也就是要扫描整个哈希表。如果没有溢出的桶，而且`map`的`key`和`value`都不包含指针时，就可以直接标记整个哈希表的颜色(比如用三色标记法)。但是哈希表采用了链地址法解决哈希问题，而且溢出的桶总是要存在的。所以就利用`extra`结构体的`overflow`指针来保存这些溢出的桶，并把`bmap`结构体的`overflow`指针类型变成一个`unitptr`类型。于是整个`bmap`就完全没有指针了，也就不会在 GC 期间被扫描。

 ![](哈希表/Pasted%20image%2020220812224639.png)

### 初始化
两种方法：字面量和进行时

#### 字面量
```go
hash := map[string]int{
	"1": 2,
	"3": 4,
	"5": 6,
}
```

当哈希表中的元素数量少于或者等于 25 个时，编译器会将字面量初始化的结构体转换成以下的代码，将所有的键值对一次加入到哈希表中：

```go
hash := make(map[string]int, 3)
hash["1"] = 2
hash["3"] = 4
hash["5"] = 6
```

这种初始化的方式与数组和切片几乎完全相同，由此看来集合类型的初始化在 Go 语言中有着相同的处理逻辑。一旦哈希表中元素的数量超过了 25 个，编译器会创建两个数组分别存储键和值，这些键值对会通过如下所示的 `for` 循环加入哈希：

```go
hash := make(map[string]int, 26)
vstatk := []string{"1", "2", "3", ... ， "26"}
vstatv := []int{1, 2, 3, ... , 26}
for i := 0; i < len(vstak); i++ {
    hash[vstatk[i]] = vstatv[i]
}
```

这里展开的两个切片 `vstatk` 和 `vstatv` 还会被编辑器继续展开，不过无论使用哪种方法，使用字面量初始化的过程都会使用 `make` 来创建新的哈希并通过最原始的 `[]` 语法向哈希追加元素。

#### 运行时
创建的哈希被分配到栈上并且其容量小于 `BUCKETSIZE = 8` 时，Go 语言在编译阶段会使用如下方式快速初始化哈希，这也是编译器对小容量的哈希做的优化：

```go
var h *hmap
var hv hmap
var bv bmap
h := &hv
b := &bv
h.buckets = b
h.hash0 = fashtrand0()
```

只要我们使用 `make` 创建哈希，Go 语言编译器都会在类型检查期间将它们转换成 `runtime.makemap`，使用字面量初始化哈希也只是语言提供的辅助工具，最后调用的都是 `runtime.makemap`

```go
func makemap(t *maptype, hint int, h *hmap) *hmap {
	mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size)
	if overflow || mem > maxAlloc {
		hint = 0
	}

	if h == nil {
		h = new(hmap)
	}
	h.hash0 = fastrand()

	B := uint8(0)
	for overLoadFactor(hint, B) {
		B++
	}
	h.B = B

	if h.B != 0 {
		var nextOverflow *bmap
		h.buckets, nextOverflow = makeBucketArray(t, h.B, nil)
		if nextOverflow != nil {
			h.extra = new(mapextra)
			h.extra.nextOverflow = nextOverflow
		}
	}
	return h
}
```

这个函数会按照下面的步骤执行：
1. 计算哈希占用的内存是否溢出或者超出能分配的最大值
2. 调用 `runtime.fastrand` 获取一个随机的哈希种子
3. 根据传入的 `hint` 计算出需要的最小需要的桶的数量
4. 使用 `runtime.makeBucketArray` 创建用于保存桶的数组

根据传入的 B 计算出的需要创建的桶数量并在内存中分配一片连续的空间用于存储数据

```go
func makeBucketArray(t *maptype, b uint8, dirtyalloc unsafe.Pointer) 
	(buckets unsafe.Pointer, nextOverflow *bmap) {
	base := bucketShift(b)
	nbuckets := base
	// 额外创建一部分溢出桶
	if b >= 4 {
		nbuckets += bucketShift(b - 4)
		sz := t.bucket.size * nbuckets
		up := roundupsize(sz)
		if up != sz {
			nbuckets = up / t.bucket.size
		}
	}

    // 数据较少、使用溢出桶的可能性较低，会省略创建的过程以减少额外开销
	buckets = newarray(t.bucket, int(nbuckets))
	if base != nbuckets {
		nextOverflow = (*bmap)(add(buckets, base*uintptr(t.bucketsize)))
		last := (*bmap)(add(buckets, (nbuckets-1)*uintptr(t.bucketsize)))
		last.setoverflow(t, (*bmap)(buckets))
	}
	return buckets, nextOverflow
}
```

根据上述代码，我们能确定在正常情况下，正常桶和溢出桶在内存中的存储空间是连续的。

### 读写操作
哈希表的访问一般都是通过下标或者遍历进行的：

```go
_ = hash[key]

for k, v := range hash {
    // k, v
}
```

这两种方式完全不同，前者需要知道哈希的键并且一次只能获取单个键对应的值，而后者可以遍历哈希中的全部键值对，访问数据时也不需要预先知道哈希的键。在这里我们会介绍前一种访问方式，第二种访问方式会在 `range` 一节中详细分析。

#### 访问
编译的类型检查期间，`hash[key]` 以及类似的操作都会被转换成哈希的 `OINDEXMAP` 操作，然后在中间代码生成阶段将这些 `OINDEXMAP` 操作转换成如下的代码：

```go
v     := hash[key] // => v     := *mapaccess1(maptype, hash, &key)
v, ok := hash[key] // => v, ok := mapaccess2(maptype, hash, &key)
```

```go
func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {
	alg := t.key.alg
	// 获取键对应的哈希值
	hash := alg.hash(key, uintptr(h.hash0))
	// 桶序号
	m := bucketMask(h.B)
	b := (*bmap)(add(h.buckets, (hash&m)*uintptr(t.bucketsize)))
	// 高8位
	top := tophash(hash)
	
bucketloop:
    // 依次遍历正常桶和溢出桶中的数据
	for ; b != nil; b = b.overflow(t) {
		// 遍历每个桶中的8个数据
		for i := uintptr(0); i < bucketCnt; i++ {
			// 先比较哈希的高 8 位和桶中存储的tophash，加速访问
			if b.tophash[i] != top {
				if b.tophash[i] == emptyRest {
					break bucketloop
				}
				continue
			}
			// 比较传入的和桶中的值以加速数据的读写
			k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))
			if alg.equal(key, k) {
				v := add(unsafe.Pointer(b), 
				dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize))
				return v
			}
		}
	}
	return unsafe.Pointer(&zeroVal[0])
}
```

每一个桶都是一整片的内存空间，当发现桶中的 `tophash` 与传入键的 `tophash` 匹配之后，我们会通过指针和偏移量获取哈希中存储的键 `keys[0]` 并与 `key` 比较，如果两者相同就会获取目标值的指针 `values[0]` 并返回。

![](哈希表/Pasted%20image%2020220812235059.png)

另一个同样用于访问哈希表中数据的 `runtime.mapaccess2` 只是在 `runtime.mapaccess1` 的基础上多返回了一个标识键值对是否存在的 `bool` 值：

```go
func mapaccess2(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, bool) {
	// ...
	// 与 mapaccess1 一致
bucketloop:
	for ; b != nil; b = b.overflow(t) {
		for i := uintptr(0); i < bucketCnt; i++ {
			if b.tophash[i] != top {
				if b.tophash[i] == emptyRest {
					break bucketloop
				}
				continue
			}
			k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))
			if alg.equal(key, k) {
				v := add(unsafe.Pointer(b), 
				dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize))
				return v, true
			}
		}
	}
	return unsafe.Pointer(&zeroVal[0]), false
}
```

#### 写入
当形如 `hash[k]` 表达式出现在赋值符号左侧时，该表达式会在编译期间转换成 `runtime.mapassign`函数的调用，返回新创建的`key`对应的`val`地址，或者旧的`val`的地址。

```go
func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {
	// 拿到哈希值
	alg := t.key.alg
	hash := alg.hash(key, uintptr(h.hash0))
	
	h.flags ^= hashWriting

again:
	// 计算桶号 
	bucket := hash & bucketMask(h.B)
	b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize)))
	top := tophash(hash)
	
	// 目标元素的在桶中的索引
	var inserti *uint8
	// 要存放键值对的地址
	var insertk unsafe.Pointer
	var val unsafe.Pointer
bucketloop:
	for {
		// 遍历一个桶中的 8 个 kv
		for i := uintptr(0); i < bucketCnt; i++ {
			// 不是第 i 个
			if b.tophash[i] != top {
				// 第 i 个是空的
				if isEmpty(b.tophash[i]) && inserti == nil {
					inserti = &b.tophash[i]
					insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))
					val = add(unsafe.Pointer(b), 
					dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize))
				}
				// 第 i 个是空的
				if b.tophash[i] == emptyRest {
					break bucketloop
				}
				continue
			}
			k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))
			// 不是相同的 key 地址
			if !alg.equal(key, k) {
				continue
			}
			// 是相同的 key 地址
			val = add(unsafe.Pointer(b), 
			dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize))
			// 直接把值的地址返回
			goto done
		}
		// 下一个溢出桶
		ovf := b.overflow(t)
		if ovf == nil {
			break
		}
		b = ovf
	}
	// 当前桶满了
	if inserti == nil {
	    // 创建新的桶
		newb := h.newoverflow(t, b)
		inserti = &newb.tophash[0]
		insertk = add(unsafe.Pointer(newb), dataOffset)
		val = add(insertk, bucketCnt*uintptr(t.keysize))
	}

	// 当前的 key 不存在，
    // 将键移动到对应的内存空间
	typedmemmove(t.key, insertk, key)
	*inserti = top
	h.count++

done:
	return val
}
```

真正的赋值操作是在编译期间插入的

```go
00018 (+5) CALL runtime.mapassign_fast64(SB)
00020 (5) MOVQ 24(SP), DI               ;; DI = &value
00026 (5) LEAQ go.string."88"(SB), AX   ;; AX = &"88"
00027 (5) MOVQ AX, (DI)                 ;; *DI = AX
```

`runtime.mapassign_fast64`  `runtime.mapassign` 函数的逻辑差不多，我们需要关注的是后面的三行代码：
1. `24(SP)` 是该函数返回的值地址
2. `LEAQ` 指令将字符串的地址存储到寄存器 `AX` 中
3. `MOVQ` 指令将字符串 `88` 存储到了目标地址上完成了这次哈希的写入

#### 扩容
介绍哈希的写入过程时其实省略了扩容操作，随着哈希表中元素的逐渐增加，哈希的性能会逐渐恶化，所以我们需要更多的桶和更大的内存保证哈希的读写性能：

```go
func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {
	// ...
	// 判断当前没有正在扩容，避免二次扩容的混乱
	if !h.growing() && (overLoadFactor(h.count+1, h.B) || 
		tooManyOverflowBuckets(h.noverflow, h.B)) {
		hashGrow(t, h)
		goto again
	}
	// ...
}
```

以下两种情况发生时触发哈希的扩容：
1. 装载因子已经超过 `6.5`
2. 哈希使用了太多溢出桶

如果这次扩容是溢出的桶太多导致的，那么这次扩容就是等量扩容 `sameSizeGrow`，`sameSizeGrow` 是一种特殊情况下发生的扩容，当我们持续向哈希中插入数据并将它们全部删除时，如果哈希表中的数据量没有超过阈值，就会不断积累溢出桶造成缓慢的内存泄漏。`sameSizeGrow` 通过复用已有的哈希扩容机制解决该问题，一旦哈希中出现了过多的溢出桶，它会创建新桶保存数据，垃圾回收会清理老的溢出桶并释放内存。

```go
func hashGrow(t *maptype, h *hmap) {
	bigger := uint8(1)
	if !overLoadFactor(h.count+1, h.B) {
		bigger = 0
		h.flags |= sameSizeGrow
	}
	oldbuckets := h.buckets

	// 创造一组新桶和预创建的溢出桶
	newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil)

	h.B += bigger
	h.flags = flags
	h.oldbuckets = oldbuckets
	h.buckets = newbuckets
	h.nevacuate = 0
	h.noverflow = 0

	h.extra.oldoverflow = h.extra.overflow
	h.extra.overflow = nil
	h.extra.nextOverflow = nextOverflow
}
```

哈希在扩容的过程中会创建一组新桶和预创建的溢出桶，随后将原有的桶数组设置到 `oldbuckets` 上并将新的空桶设置到 `buckets` 上，溢出桶也使用了相同的逻辑更新，下图展示了触发扩容后的哈希：

![](哈希表/Pasted%20image%2020220813231433.png)

表的数据迁移的过程在是 `runtime.evacuate` 中完成的，它会对传入桶中的元素进行再分配

![](哈希表/Pasted%20image%2020220813232054.png)

```go
func evacuate(t *maptype, h *hmap, oldbucket uintptr) {
	b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)))
	// newbit 可以区分等量扩容和增量扩容
	newbit := h.noldbuckets()
	if !evacuated(b) {
		// 将一个旧桶中的数据分流到两个新桶
		var xy [2]evacDst
		
		// x 和 y 是两个桶
		x := &xy[0]
		x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize)))
		x.k = add(unsafe.Pointer(x.b), dataOffset)
		x.v = add(x.k, bucketCnt*uintptr(t.keysize))

		y := &xy[1]
		y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize)))
		y.k = add(unsafe.Pointer(y.b), dataOffset)
		y.v = add(y.k, bucketCnt*uintptr(t.keysize))

		// 遍历所有桶和溢出桶
		for ; b != nil; b = b.overflow(t) {
			k := add(unsafe.Pointer(b), dataOffset)
			v := add(k, bucketCnt*uintptr(t.keysize))
			// 8 个 kv
			for i := 0; i < bucketCnt; i, k, v = i+1, 
				add(k, uintptr(t.keysize)), add(v, uintptr(t.valuesize)) {
				top := b.tophash[i]
				k2 := k
				// 判断是否使用第二个桶
				var useY uint8
				hash := t.key.alg.hash(k2, uintptr(h.hash0))
				if hash&newbit != 0 {
					useY = 1
				}
				b.tophash[i] = evacuatedX + useY
				dst := &xy[useY]

				if dst.i == bucketCnt {
					dst.b = h.newoverflow(t, dst.b)
					dst.i = 0
					dst.k = add(unsafe.Pointer(dst.b), dataOffset)
					dst.v = add(dst.k, bucketCnt*uintptr(t.keysize))
				}
				dst.b.tophash[dst.i&(bucketCnt-1)] = top
				typedmemmove(t.key, dst.k, k)
				typedmemmove(t.elem, dst.v, v)
				dst.i++
				dst.k = add(dst.k, uintptr(t.keysize))
				dst.v = add(dst.v, uintptr(t.valuesize))
			}
		}
		//...
}
```

`runtime.evacuate` 最后会调用 `runtime.advanceEvacuationMark` 增加哈希的 `nevacuate` 计数器并在所有的旧桶都被分流后清空哈希的 `oldbuckets` 和 `oldoverflow`

```go
func advanceEvacuationMark(h *hmap, t *maptype, newbit uintptr) {
	h.nevacuate++
	stop := h.nevacuate + 1024
	if stop > newbit {
		stop = newbit
	}
	for h.nevacuate != stop && bucketEvacuated(t, h, h.nevacuate) {
		h.nevacuate++
	}
	if h.nevacuate == newbit { // newbit == # of oldbuckets
		h.oldbuckets = nil
		if h.extra != nil {
			h.extra.oldoverflow = nil
		}
		h.flags &^= sameSizeGrow
	}
}
```

之前在分析哈希表访问函数 `runtime.mapaccess1` 时其实省略了扩容期间获取键值对的逻辑，当哈希表的 `oldbuckets` 存在时，会先定位到旧桶并在该桶没有被分流时从中获取键值对。因为旧桶中的元素还没有被分流，其中还保存着我们需要使用的数据，所以旧桶会替代新创建的空桶提供数据。

```go
func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {
	// ...
	alg := t.key.alg
	hash := alg.hash(key, uintptr(h.hash0))
	m := bucketMask(h.B)
	b := (*bmap)(add(h.buckets, (hash&m)*uintptr(t.bucketsize)))
	if c := h.oldbuckets; c != nil {
		if !h.sameSizeGrow() {
			m >>= 1
		}
		oldb := (*bmap)(add(c, (hash&m)*uintptr(t.bucketsize)))
		if !evacuated(oldb) {
			b = oldb
		}
	}
bucketloop:
	// ...
}
```

我们在 `runtime.mapassign` 函数中也省略了一段逻辑，当哈希表正在处于扩容状态时，每次向哈希表写入值时都会触发 `runtime.growWork` 增量拷贝哈希表中的内容：

```go
func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {
	// ...
again:
	bucket := hash & bucketMask(h.B)
	if h.growing() {
		growWork(t, h, bucket)
	}
	// ...
}
```

除了写入操作之外，删除操作也会在哈希表扩容期间触发 `runtime.growWork`，触发的方式和代码与这里的逻辑几乎完全相同，都是计算当前值所在的桶，然后拷贝桶中的元素。

简单总结一下哈希表扩容的设计和原理，哈希在存储元素过多时会触发扩容操作，每次都会将桶的数量翻倍，扩容过程不是原子的，而是通过 `runtime.growWork` 增量触发的，在扩容期间访问哈希表时会使用旧桶，向哈希表写入数据时会触发旧桶元素的分流。除了这种正常的扩容之外，为了解决大量写入、删除造成的内存泄漏问题，哈希引入了 `sameSizeGrow` 这一机制，在出现较多溢出桶时会整理哈希的内存减少空间的占用。

#### 删除
如果想要删除哈希中的元素，就需要使用 Go 语言中的 `delete` 关键字，这个关键字的唯一作用就是将某一个键对应的元素从哈希表中删除，无论是该键对应的值是否存在，这个内建的函数都不会返回任何的结果。

![](哈希表/Pasted%20image%2020220814162707.png)

编译期间，`delete` 关键字会被转换成操作为 `ODELETE` 的节点，而 `ODELETE` 节点会转换成其中的一个：
1. `runtime.mapdelete`
2. `mapdelete_faststr`
3. `mapdelete_fast32`
4. `mapdelete_fast64`

这些函数的实现其实差不多，哈希表的删除逻辑与写入逻辑很相似，只是触发哈希的删除需要使用关键字，如果在删除期间遇到了哈希表的扩容，就会分流桶中的元素，分流结束之后会找到桶中的目标元素完成键值对的删除工作。

```go
func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) {
	// ...
	// 如果正在扩容 触发分流
	if h.growing() {
		growWork(t, h, bucket)
	}
	// ...
search:
	for ; b != nil; b = b.overflow(t) {
		for i := uintptr(0); i < bucketCnt; i++ {
			if b.tophash[i] != top {
				if b.tophash[i] == emptyRest {
					break search
				}
				continue
			}
			k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))
			k2 := k
			if !alg.equal(key, k2) {
				continue
			}
			*(*unsafe.Pointer)(k) = nil
			v := add(unsafe.Pointer(b), 
			dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize))
			*(*unsafe.Pointer)(v) = nil
			b.tophash[i] = emptyOne
			...
		}
	}
}
```

### 小结
Go 语言使用拉链法来解决哈希碰撞的问题实现了哈希表，它的访问、写入和删除等操作都在编译期间转换成了运行时的函数或者方法。哈希在每一个桶中存储键对应哈希的前 8 位，当对哈希进行操作时，这些 `tophash` 就成为可以帮助哈希快速遍历桶中元素的缓存。

哈希表的每个桶都只能存储 8 个键值对，一旦当前哈希的某个桶超出 8 个，新的键值对就会存储到哈希的溢出桶中。随着键值对数量的增加，溢出桶的数量和哈希的装载因子也会逐渐升高，超过一定范围就会触发扩容，扩容会将桶的数量翻倍，元素再分配的过程也是在调用写操作时增量进行的，不会造成性能的瞬时巨大抖动。